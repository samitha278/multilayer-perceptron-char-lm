{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samitha278/multilayer-perceptron-char-lm/blob/main/mlp_backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ChBbac4y8PPq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://github.com/samitha278/multilayer-perceptron-char-lm/blob/main/data/names.txt"
      ],
      "metadata": {
        "id": "x6GhEWW18aCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a2376b-e601-46da-d2a8-ab2c88f66379"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-23 13:08:19--  https://github.com/samitha278/multilayer-perceptron-char-lm/blob/main/data/names.txt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt               [ <=>                ] 560.10K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-08-23 13:08:19 (6.77 MB/s) - ‘names.txt’ saved [573545]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "klmu3ZG08PPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5feb168-6f90-4110-a2f5-278c7baaf2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2090\n",
            "392942\n",
            "['', '', '', '', '', '', '<!DOCTYPE html>', '<html']\n"
          ]
        }
      ],
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(len(words))\n",
        "print(max(len(w) for w in words))\n",
        "print(words[:8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BCQomLE_8PPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4cf9afc-fa69-43b4-f0de-5ec7c8ec99a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: ' ', 2: '!', 3: '\"', 4: '#', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 0: '.', 15: '/', 16: '0', 17: '1', 18: '2', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9', 26: ':', 27: ';', 28: '<', 29: '=', 30: '>', 31: '?', 32: '@', 33: 'A', 34: 'B', 35: 'C', 36: 'D', 37: 'E', 38: 'F', 39: 'G', 40: 'H', 41: 'I', 42: 'J', 43: 'K', 44: 'L', 45: 'M', 46: 'N', 47: 'O', 48: 'P', 49: 'Q', 50: 'R', 51: 'S', 52: 'T', 53: 'U', 54: 'V', 55: 'W', 56: 'X', 57: 'Y', 58: 'Z', 59: '[', 60: ']', 61: '_', 62: '`', 63: 'a', 64: 'b', 65: 'c', 66: 'd', 67: 'e', 68: 'f', 69: 'g', 70: 'h', 71: 'i', 72: 'j', 73: 'k', 74: 'l', 75: 'm', 76: 'n', 77: 'o', 78: 'p', 79: 'q', 80: 'r', 81: 's', 82: 't', 83: 'u', 84: 'v', 85: 'w', 86: 'x', 87: 'y', 88: 'z', 89: '{', 90: '}', 91: '·', 92: '’', 93: '…'}\n",
            "93\n"
          ]
        }
      ],
      "source": [
        "#character mapping\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the dataset"
      ],
      "metadata": {
        "id": "NUv_FZ9cyAV_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V_zt2QHr8PPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa13356-93c3-4007-9ea3-8193d021fd54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([146293, 3]) torch.Size([146293])\n",
            "torch.Size([19691, 3]) torch.Size([19691])\n",
            "torch.Size([407551, 3]) torch.Size([407551])\n"
          ]
        }
      ],
      "source": [
        "block_size = 3 # context length\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix]\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "random.seed(278)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build MLP"
      ],
      "metadata": {
        "id": "tPYGkr6KxUeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10      # dimensionality of the character embedding vectors\n",
        "n_hidden = 64    # number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "\n",
        "\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 useless because of BN\n",
        "\n",
        "\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "\n",
        "\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isqri0djwKfA",
        "outputId": "0266b044-b9eb-4b97-9d1b-6ed76f1f7447"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward pass"
      ],
      "metadata": {
        "id": "wYSPOzkAy1aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "n = batch_size\n",
        "#minibatch\n",
        "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]"
      ],
      "metadata": {
        "id": "UHEreoPY8heG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "emb = C[Xb]                         # characters into vectors\n",
        "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "\n",
        "\n",
        "# Linear layer 1\n",
        "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "\n",
        "# BatchNorm layer\n",
        "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff**2\n",
        "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # Bessel's correction\n",
        "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "\n",
        "# # hidden layer - Non-linearity\n",
        "h = torch.tanh(hpreact)\n",
        "\n",
        "\n",
        "# Linear layer 2\n",
        "logits = h @ W2 + b2 # output layer\n",
        "\n",
        "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
        "logit_maxes = logits.max(1, keepdim=True).values\n",
        "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1\n",
        "\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "8_YneSzWxyrd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch backward pass\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1AmtXHGFEhX",
        "outputId": "710b1f35-7dee-494c-d49c-2262fe37d87a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5734, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing manual gradients to PyTorch gradients"
      ],
      "metadata": {
        "id": "6NNJvPKIGsea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "Qe1GITjEFDlm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backprop - manually\n",
        "\n"
      ],
      "metadata": {
        "id": "MDrB4TzJHA6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2UA0Xy9JHhW",
        "outputId": "678a4198-ffba-4b12-ac82-2f785ff31845"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 93])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n),Yb] = -1.0/n\n",
        "\n",
        "\n",
        "\n",
        "dprobs = dlogprobs * (1.0/probs)\n",
        "\n",
        "dcounts = dprobs * counts_sum_inv\n",
        "\n",
        "dcounts_sum_inv = (dprobs * counts).sum(1,keepdims = True)\n",
        "\n",
        "\n",
        "dcounts_sum = dcounts_sum_inv * (-counts_sum**-2)\n",
        "\n",
        "dcounts += dcounts_sum * torch.ones_like(counts)\n",
        "\n",
        "\n",
        "dnorm_logits = dcounts * counts  #norm_logits.exp()\n",
        "\n",
        "\n",
        "\n",
        "dlogit_maxes = dnorm_logits * -1 * torch.ones_like(logits)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# dlogits = dnorm_logits\n",
        "# dh = dlogits @ W2.T\n",
        "# dW2 = dlogits.T  @ h\n",
        "# db2 = dlogits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cmp('logprobs', dlogprobs, logprobs)\n",
        "cmp('probs', dprobs, probs)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "cmp('counts', dcounts, counts)\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)\n",
        "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
        "# cmp('logits', dlogits, logits)\n",
        "# cmp('h', dh, h)\n",
        "# cmp('W2', dW2, W2)\n",
        "# cmp('b2', db2, b2)\n",
        "# cmp('hpreact', dhpreact, hpreact)\n",
        "# cmp('bngain', dbngain, bngain)\n",
        "# cmp('bnbias', dbnbias, bnbias)\n",
        "# cmp('bnraw', dbnraw, bnraw)\n",
        "# cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "# cmp('bnvar', dbnvar, bnvar)\n",
        "# cmp('bndiff2', dbndiff2, bndiff2)\n",
        "# cmp('bndiff', dbndiff, bndiff)\n",
        "# cmp('bnmeani', dbnmeani, bnmeani)\n",
        "# cmp('hprebn', dhprebn, hprebn)\n",
        "# cmp('embcat', dembcat, embcat)\n",
        "# cmp('W1', dW1, W1)\n",
        "# cmp('b1', db1, b1)\n",
        "# cmp('emb', demb, emb)\n",
        "# cmp('C', dC, C)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGHtWBseG3Mv",
        "outputId": "d7de18b0-f6a0-4440-8bc2-72128f365805"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logit_maxes     | exact: False | approximate: False | maxdiff: 0.031169598922133446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit_maxes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVY_bXBBe4er",
        "outputId": "e6fb0d28-7a9a-4852-aee7-45514a33a9ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2956],\n",
              "        [1.0431],\n",
              "        [1.0291],\n",
              "        [0.9757],\n",
              "        [1.2925],\n",
              "        [1.3569],\n",
              "        [1.2586],\n",
              "        [1.5214],\n",
              "        [1.6282],\n",
              "        [1.2867],\n",
              "        [1.2438],\n",
              "        [1.3182],\n",
              "        [1.1812],\n",
              "        [1.5553],\n",
              "        [0.9487],\n",
              "        [1.3382],\n",
              "        [1.0264],\n",
              "        [1.1072],\n",
              "        [1.5294],\n",
              "        [1.1754],\n",
              "        [1.4103],\n",
              "        [1.5553],\n",
              "        [1.1048],\n",
              "        [1.6779],\n",
              "        [1.6396],\n",
              "        [1.1186],\n",
              "        [1.1915],\n",
              "        [1.2986],\n",
              "        [1.5553],\n",
              "        [0.8035],\n",
              "        [0.8696],\n",
              "        [1.3355]], grad_fn=<MaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dprobs * counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDDivDDlemYV",
        "outputId": "e980565d-1c42-46ea-ae81-72de66f16737"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [-1.3944,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO7wz0ygdq-w",
        "outputId": "a6c7c77a-cd8c-4808-936d-9c89f5b0de7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [-0.0312,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dprobs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZWE8maSdt-2",
        "outputId": "46a5afee-8664-4c7d-b704-94db69d1050f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [-2.5177,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1mvR6ukFeNQE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum_inv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aML6U0xa3Xh",
        "outputId": "a08bdc00-e85c-4fdf-e14d-8ac051356892"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9447],\n",
              "        [-1.0509],\n",
              "        [-1.0467],\n",
              "        [-1.1663],\n",
              "        [-0.9413],\n",
              "        [-0.8533],\n",
              "        [-0.9385],\n",
              "        [-0.6914],\n",
              "        [-0.6044],\n",
              "        [-0.8829],\n",
              "        [-0.9372],\n",
              "        [-0.9675],\n",
              "        [-1.0209],\n",
              "        [-0.7557],\n",
              "        [-1.2060],\n",
              "        [-0.8738],\n",
              "        [-1.1517],\n",
              "        [-1.0705],\n",
              "        [-0.7144],\n",
              "        [-0.9766],\n",
              "        [-0.8791],\n",
              "        [-0.7557],\n",
              "        [-1.0333],\n",
              "        [-0.6549],\n",
              "        [-0.6978],\n",
              "        [-1.0695],\n",
              "        [-0.9309],\n",
              "        [-0.8978],\n",
              "        [-0.7557],\n",
              "        [-1.3944],\n",
              "        [-1.2086],\n",
              "        [-0.8566]], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dprobs * counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ot5jKgpbyTo",
        "outputId": "cc7d4237-655d-4faa-e9e2-eae252da76ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [-1.3944,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs * (1.0/probs) * counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTCQxQFvWIeM",
        "outputId": "2bd951fd-756f-43fc-d09f-ef25160e9971"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [-1.3944,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts_sum_inv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyMi_6XXZrbE",
        "outputId": "d8ba98d5-cc2a-4d11-c2d1-74af37e8848b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0331],\n",
              "        [0.0297],\n",
              "        [0.0299],\n",
              "        [0.0268],\n",
              "        [0.0332],\n",
              "        [0.0366],\n",
              "        [0.0333],\n",
              "        [0.0452],\n",
              "        [0.0517],\n",
              "        [0.0354],\n",
              "        [0.0333],\n",
              "        [0.0323],\n",
              "        [0.0306],\n",
              "        [0.0414],\n",
              "        [0.0259],\n",
              "        [0.0358],\n",
              "        [0.0271],\n",
              "        [0.0292],\n",
              "        [0.0437],\n",
              "        [0.0320],\n",
              "        [0.0355],\n",
              "        [0.0414],\n",
              "        [0.0302],\n",
              "        [0.0477],\n",
              "        [0.0448],\n",
              "        [0.0292],\n",
              "        [0.0336],\n",
              "        [0.0348],\n",
              "        [0.0414],\n",
              "        [0.0224],\n",
              "        [0.0259],\n",
              "        [0.0365]], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs * (1.0/probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXdpXP3jWhz3",
        "outputId": "866bac70-bdb4-4a13-fa42-d3e964beb5c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [-2.5177,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMrX_pNpG11d",
        "outputId": "a46066bd-b5db-488f-85aa-78a26693de2e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0130, 0.0097, 0.0287,  ..., 0.0099, 0.0062, 0.0038],\n",
              "        [0.0065, 0.0179, 0.0114,  ..., 0.0029, 0.0063, 0.0077],\n",
              "        [0.0054, 0.0149, 0.0043,  ..., 0.0094, 0.0067, 0.0109],\n",
              "        ...,\n",
              "        [0.0124, 0.0067, 0.0161,  ..., 0.0120, 0.0109, 0.0105],\n",
              "        [0.0060, 0.0093, 0.0106,  ..., 0.0079, 0.0122, 0.0041],\n",
              "        [0.0091, 0.0064, 0.0083,  ..., 0.0145, 0.0128, 0.0115]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1.0/probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_i8ojVkWPFE",
        "outputId": "99977000-7ef7-4a59-ef0e-8720531b0efa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 76.7810, 103.1417,  34.8359,  ..., 101.1068, 161.6606, 264.5447],\n",
              "        [153.5139,  56.0160,  87.6383,  ..., 344.0364, 158.0789, 130.6225],\n",
              "        [184.1756,  66.9186, 235.2254,  ..., 106.6008, 148.8115,  91.7553],\n",
              "        ...,\n",
              "        [ 80.5650, 148.2551,  62.0806,  ...,  83.4420,  91.8387,  95.6044],\n",
              "        [166.4879, 106.9857,  94.2314,  ..., 126.8341,  82.0014, 241.9802],\n",
              "        [109.9942, 155.3180, 120.5484,  ...,  69.1642,  78.2783,  86.6866]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qH-7tw-pWS9v"
      },
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}